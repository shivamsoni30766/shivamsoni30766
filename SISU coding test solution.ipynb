{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Name: Shivam Soni</span>\n",
    "\n",
    "## <span style=\"color:green\">SISU coding solution - Data engineering</span>\n",
    "\n",
    "###  <span style=\"color:green\"> 1. Libraries imported</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the csv file as pandas data frame\n",
    "transaction_df = pd.read_csv(\"Transaction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> 2. Exploratory data analysis and Data cleaning </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there are __**30320**__ rows or records and __**19**__ columns in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we the following to clean the data:\n",
    "1. Delete xyz and nan values records for Account Status\n",
    "2. Delete nan value records for Property Type\n",
    "3. Check the format of each row, if anamoly detected then convert into the right format\n",
    "4. Remove the unnamed columns from the tail end of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last two columns are being read as Unnamed:17 & Unnamed:18 which are deleted below\n",
    "del transaction_df[transaction_df.columns[len(transaction_df.columns)-2]]\n",
    "del transaction_df[transaction_df.columns[len(transaction_df.columns)-1]]\n",
    "\n",
    "#Removing unnecessary spaces from the header\n",
    "transaction_df.columns = transaction_df.columns.str.replace(' ','')\n",
    "\n",
    "#Loading all the column names into a list\n",
    "column_list = list(transaction_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful columns into a list\n",
    "len(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring dictionary to store unique values of relevant columns\n",
    "dict_of_unique_values = {}\n",
    "for number in range(len(column_list)-1):\n",
    "    req_no = column_list[number] \n",
    "    dict_of_unique_values[req_no] = list(transaction_df[req_no].unique())\n",
    "    \n",
    "#Displaying unique values for relevant columns\n",
    "for number in range(len(column_list)-1):\n",
    "    if not number in [0,2,7,10,13,14]: \n",
    "        print(column_list[number]+\" ---> \"+str(dict_of_unique_values[column_list[number]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the indexes of na values in Account status and property type\n",
    "index_na_acc_status = list(np.where(transaction_df['Accountstatus'].isna()))\n",
    "index_na_prp_status = list(np.where(transaction_df['PropertyTYPE'].isna()))\n",
    "\n",
    "#Converting the indexes into a list\n",
    "index_na_acc_status = list(index_na_acc_status)\n",
    "index_na_prp_status = list(index_na_prp_status)\n",
    "\n",
    "\n",
    "temp_len = len(index_na_acc_status[0])\n",
    "temp_len_1 = len(index_na_prp_status[0])\n",
    "\n",
    "del_index_list = []\n",
    "    \n",
    "for i in range(temp_len):\n",
    "    del_index_list.append(index_na_acc_status[0][i])\n",
    "for i in range(temp_len_1):\n",
    "    del_index_list.append(index_na_prp_status[0][i])\n",
    "    \n",
    "transaction_df = transaction_df.drop(del_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code tab is declaring a function to get the index number of the columns\n",
    "\n",
    "#Function to find index of the column\n",
    "def find_index(string):\n",
    "    return int(column_list.index(string))\n",
    "\n",
    "#Function to convert string columns into date stamp\n",
    "def convert_to_date(column_name):\n",
    "    transaction_df[column_name] = pd.to_datetime(transaction_df[column_name])\n",
    "    return transaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of agents\n",
    "no_of_agents = len(dict_of_unique_values[column_list[find_index(\"AgentID\")]])\n",
    "print(\"There are \"+str(no_of_agents)+\" Agents in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> 3. Writing records in JSON one at a time and creating batch files for every 1000 records </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting any existing files \n",
    "for i in range(round(((len(transaction_df)+4)/1000)+2)):\n",
    "    if os.path.isfile(\"{}.json\".format(i+1)):\n",
    "        os.remove(\"{}.json\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Task number 2,3,4 & 5 are done in this block of code.\n",
    "n =1\n",
    "\n",
    "#Creating new files as per instructions\n",
    "for i in transaction_df.index:\n",
    "    \n",
    "    #Watching the above task in the output terminal\n",
    "    print(\"{}\\n\".format(i)+  transaction_df.loc[i].to_json()+ \"\\n\\n\" )\n",
    "    \n",
    "    #Writing the data in JSON one record at a time\n",
    "    #Naming it 1.json, 2.json according to the batch of 1000 records\n",
    "    transaction_df.loc[i].to_json(\"{}.json\".format(n))\n",
    "    \n",
    "    #Creating a JSON file for every 1000 records\n",
    "    if (int(i/1000) == n):\n",
    "        n = n + 1\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> 3. Converting the date columns into date format and calculating the response time to show list of post codes based on fastest response </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring the list of columns to be converted from string to date\n",
    "str_to_date_list = [\"RequestDate\",\"lastUpdatedDate\",\"ImplementedDate\"]\n",
    "\n",
    "#Using the above declared function to convert the declared list of columns to date\n",
    "for n in str_to_date_list:\n",
    "    convert_to_date(n)\n",
    "\n",
    "#Adding a new row to calculate the response time by the agent\n",
    "transaction_df['ResponseTime'] = transaction_df['RequestDate'] - transaction_df['ImplementedDate']\n",
    "\n",
    "#Getting just the number of days as a difference betweeen Request date and implemented date\n",
    "transaction_df[\"ResponseTime\"] = [transaction_df.iloc[i][\"ResponseTime\"].days for i in range(len(transaction_df))]\n",
    "transaction_df[\"ResponseTime\"] = [abs(transaction_df.iloc[i][\"ResponseTime\"]) for i in range(len(transaction_df))]\n",
    "\n",
    "#Displaying list of codes based on fastest response which is the minimum number of days taken from requested to implemented\n",
    "transaction_df.groupby(by=\"PostCode\")[\"ResponseTime\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> 4. Calculating and displaying top agents based on Post codes and Amount </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying top agents with respect to Post code and Agent ID\n",
    "\n",
    "temp_df = transaction_df.groupby(by=[\"PostCode\",\"AgentID\"])[\"$Amount\"].sum()\n",
    "top_agents = temp_df.loc[temp_df.groupby(level=0).idxmax()]\n",
    "print(top_agents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
